{
	"published": "2025-08-17",
  "description": ""
}

# Exploiting a 40 year-old design choice to speed up vector search

A while ago, I came across a post on reddit about a user's experience [speeding up the rav1d video decoder by 1%](https://ohadravid.github.io/posts/2025-05-rav1d-faster/) and got inspired by a simple trick they used.

The hack involved replacing field-wise equality with byte-wise equality for a struct, which translated in code as a custom impl of `PartialEq`. Doing this greatly reduced the number of instructions in the resulting assembly code by almost half and translated to tangible speedups in the decoder.

So instead of this :
```rust
use zerocopy::{AsBytes}

#[derive(PartialEq, AsBytes)]
#[repr(C)]
pub struct Foo{
  a: i32,
  b: i32
}
```

You'd write :

```rust
use zerocopy::{AsBytes}

#[derive(AsBytes)]
#[repr(C)]
pub struct Foo{
  a: i32,
  b: i32
}

impl PartialEq for Foo{
  fn eq(&self, other: &Self) -> bool {
    // NOTE: `as_bytes` comes from #[derive(AsBytes)]
    self.as_bytes()  == other.as_bytes()
  }
}
```

Now when we consider the equality of two `&Foo`'s we just look at `&[u8]` slices instead of doing a field-by-field check.

This got me thinking about applying the same trick to [a vector database I'd been writing](https://github.com/nnethercott/hannoy), in which a non-negligeable amount of time is spent ordering `f32`'s to determine if an item is a nearest neighbour or not. I figured it was the perfect setting to try it out, except rather than implementing `PartialEq` I'd be implementing `Ord`.


## Rust, `f32`, `Ord`, and sadness {#background}
In rust, `f32` doesn't implement `Ord` or `Eq`. Consulting the docs on [NaN's](https://doc.rust-lang.org/std/primitive.f32.html#nan-bit-patterns) explains why :

> - It is not equal to any float, including itself! This is the reason f32 doesn’t implement the Eq trait.
> - It is also neither smaller nor greater than any float, making it impossible to sort by the default comparison operation, which is the reason f32 doesn’t implement the Ord trait. [[link]](https://doc.rust-lang.org/std/primitive.f32.html)

This is why you need a crate like [ordered-float](https://docs.rs/ordered-float/latest/ordered_float/) if you wish to work with containers like `std::collections::BinaryHeap<T>` that enforces the `T: Ord` trait bound to perform sorting internally.

`ordered-float` is great most of the time, but in the context of vector search I think it's a bit overkill.

For starters, we're only working with _non-negative_  `f32`'s coming from [distance metrics](https://en.wikipedia.org/wiki/Metric_space#Definition), not the whole representable range. For another, the `ordered-float` crate also implements `Hash` for it's `OrderedFloat<f32>` wrapper type which adds some lines of code to the final executable that we don't really need.

On top of this, the project itself is around ~3k LOC, while a [bare-bones implementation doing only what we need](https://github.com/nnethercott/hannoy/blob/main/src/ordered_float.rs) takes ~50.

## the trick {#trick}
If you're reading this article I'm assuming you know how floating point types are represented in memory, but for completeness I'll go over it again here quickly. 

Floats are generally made up of 3 components: a sign bit; some exponent bits; and some mantissa (fraction) bits. By playing around with the number of bits you allocate between the exponent and mantissa you can cover a wider [dynamic range](https://en.wikipedia.org/wiki/Dynamic_range) or achieve higher precision depending on your use-case.


<figure>
<div style="text-align: center;">
    <img src="/static/images/f32_post/f32_754.png" style="padding: 1em; width: 100%; display: block; margin: 0 auto;" >
    <!-- <figcaption> -->
    <!--   Speed comparison between my tokenizer (yellow) and popular libraries like Hugging Face and OpenAI -->
    <!-- </figcaption> -->
</div>
</figure>

To convert from a 32-bit integer back to an `f32` you use the following formula:
$$
x = (-1)^{\text{sign}}\times2^{(\text{exponent}-127)}\times\left(1+\sum_{i=1}^{23}b^{(fraction)}_{i}2^{-i} \right)
$$

While it may be true that $-x\leq x$ in f32-world, the same relationship doesn't hold when we interpret those same `f32`'s as `u32`'s. It's enough to look at the sign bit and see why; any negative number has the most significant bit set to 1 which automatically makes it larger as an integer than its positive counterpart.

This is why statements like `(f32::MAX).to_bits()` < `(-0.0f32).to_bits()` evaluate to `true`.

Ok, so we can't just compare `&[u8]`'s and call it a day.

But recall, since the all the floats we need to sort come from distance calculations, we can guarantee that they're always $\geq 0$ !

## some benchmarks {#benches}
You can find the benchmarks [here](fix-me-later).

Add flamegraph of hannoy search execution here.
